torch>=2.0.0
transformers>=4.30.0
peft>=0.7.0  # For LoRA fine-tuning
accelerate>=0.20.0  # For distributed training and model handling
datasets>=2.14.0  # For data processing
scipy>=1.10.0
numpy>=1.24.0
pandas>=2.0.0
h5py>=3.8.0
scikit-learn>=1.2.0
nltk>=3.8
sacrebleu>=2.3.0
rouge-score>=0.1.2
matplotlib>=3.7.0
seaborn>=0.12.0
tqdm>=4.65.0
tensorboard>=2.13.0
wandb>=0.15.0  # Optional: for experiment tracking
